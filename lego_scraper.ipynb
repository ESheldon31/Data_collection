{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [/Users/ESheldon/.wdm/drivers/chromedriver/mac64/100.0.4896.60/chromedriver] found in cache\n",
      "/var/folders/pk/qjr6ty3x7s58790y_7_dwl240000gn/T/ipykernel_4436/1293983630.py:37: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://ideas.lego.com/projects/9193e8c1-0546-4e73-99a2-2f89c5e2ddd3', 'https://ideas.lego.com/projects/4fab9083-ec71-46bf-80d9-3d5129626a93', 'https://ideas.lego.com/projects/8529a4b5-f36a-4779-943e-55c196e772e8', 'https://ideas.lego.com/projects/aa4cfa30-e9a2-418d-a1a0-79638e50a54f', 'https://ideas.lego.com/projects/1ef44bb0-7e5a-4484-94b6-2fee44fe3dc6']\n",
      "5\n",
      "{'id': ['2f89c5e2ddd3', '3d5129626a93', '55c196e772e8', '79638e50a54f', '2fee44fe3dc6'], 'uuid': [UUID('06d6afa6-f7f3-4fff-8e48-212ebc29c5bc'), UUID('1546c19f-41e8-4d9e-b376-c305d5fb6808'), UUID('31a10072-a1cc-4ea4-a366-c1e8051793e2'), UUID('c64214ea-5f10-43ee-9573-da1858429540'), UUID('b04bd009-adc1-4071-8394-a5167a38477d')], 'URL': ['https://ideas.lego.com/projects/9193e8c1-0546-4e73-99a2-2f89c5e2ddd3', 'https://ideas.lego.com/projects/4fab9083-ec71-46bf-80d9-3d5129626a93', 'https://ideas.lego.com/projects/8529a4b5-f36a-4779-943e-55c196e772e8', 'https://ideas.lego.com/projects/aa4cfa30-e9a2-418d-a1a0-79638e50a54f', 'https://ideas.lego.com/projects/1ef44bb0-7e5a-4484-94b6-2fee44fe3dc6']}\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium.webdriver import Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "#import requests\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common import service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "#from time import sleep, time\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "#import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import csv\n",
    "import uuid\n",
    "import urllib\n",
    "\n",
    "\n",
    "'''\n",
    "This module contains the scraper class and its methods.\n",
    "'''\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, url, search_term, headless=False):\n",
    "        options = Options()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')\n",
    "            self.driver = Chrome(ChromeDriverManager().install(), options=options)\n",
    "        else:\n",
    "            self.driver = Chrome(ChromeDriverManager().install())\n",
    "        self.url = url\n",
    "        self.search_term = search_term.upper()\n",
    "        self.driver.get(self.url)\n",
    "   \n",
    "    def open_url(self, url):\n",
    "        self.driver.get(url)\n",
    "    \n",
    "    def search(self, name=str):\n",
    "        search_bar = self.driver.find_element(By.NAME, name)\n",
    "        search_bar.click()\n",
    "        search_bar.send_keys(self.search_term)\n",
    "        search_bar.send_keys(u'\\ue007')\n",
    "\n",
    "    def click_button(self, XPATH):\n",
    "        button = self.driver.find_element(By.XPATH, XPATH)\n",
    "        button.click()\n",
    "\n",
    "    def scroll_up_top(self):\n",
    "        self.driver.execute_script(\"window.scrollTo(0,document.body.scrollTop)\")\n",
    "\n",
    "    def scroll_down_bottom(self):\n",
    "        self.driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "\n",
    "    def accept_cookies(self, frame_id, XPATH):\n",
    "        #time.sleep(2)\n",
    "        try:\n",
    "            if frame_id!=None:\n",
    "                self.switch_frame(frame_id)\n",
    "            else: pass\n",
    "            self.wait_for(XPATH)\n",
    "            self.click_button(XPATH)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "    def wait_for(self, XPATH, delay = 10):\n",
    "        try:    \n",
    "            WebDriverWait(self.driver, delay).until(EC.presence_of_element_located((By.XPATH, XPATH)))\n",
    "        except TimeoutException:\n",
    "            print('Loading took too long. Timeout occurred.')\n",
    "\n",
    "    def switch_frame(self, frame_id):\n",
    "        self.wait_for(frame_id)\n",
    "        self.driver.switchTo().frame(frame_id)\n",
    "\n",
    "    def quit(self):\n",
    "        self.driver.quit()\n",
    "\n",
    "    def next_page(self, url):\n",
    "        self.open_url(url)\n",
    "\n",
    "    def see_more(self, XPATH):\n",
    "        self.scroll_down_bottom()\n",
    "        self.click_button(XPATH)\n",
    "        \n",
    "    def explore_product_ideas(self, XPATH1, XPATH2):\n",
    "        self.click_button(XPATH1)\n",
    "        self.click_button(XPATH2)\n",
    "    \n",
    "    def infinite_scroll(self):\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            self.scroll_down_bottom()\n",
    "            time.sleep(3)   \n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "    def get_list_links(self, XPATH_container, XPATH_search_results, delay=10):\n",
    "        try: #this is causing problems when it doesn't need to press see_more\n",
    "            self.scroll_down_bottom()\n",
    "            try:\n",
    "                self.see_more('//*[@id=\"search-more\"]/a')\n",
    "                self.infinite_scroll()\n",
    "                pass\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            container = self.driver.find_element(By.XPATH, XPATH_container)\n",
    "            search_list = container.find_elements(By.XPATH, XPATH_search_results)\n",
    "\n",
    "            self.link_list = []\n",
    "\n",
    "            for result in search_list:\n",
    "                a_tag = result.find_element(By.TAG_NAME, 'a')\n",
    "                link = a_tag.get_attribute('href')\n",
    "                self.link_list.append(link)\n",
    "            \n",
    "            print(self.link_list)\n",
    "            print(len(self.link_list))\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print('No results found. Try another search term.')\n",
    "            pass #don't want it to pass. Want it to start again.\n",
    "    \n",
    "    def get_img_links(self, XPATH_wrapper, XPATH_main_image, XPATH_img_container, XPATH_thumbnails):\n",
    "        self.img_list = []\n",
    "        for link in self.link_list:\n",
    "            self.open_url(link)\n",
    "            try:\n",
    "                wrapper = self.driver.find_element(By.XPATH, XPATH_wrapper)\n",
    "                main_image = wrapper.find_elements(By.XPATH, XPATH_main_image)\n",
    "                img_tag = main_image.find_element(By.TAG_NAME, 'img')\n",
    "                img_link = img_tag.get_attribute('src')\n",
    "                self.img_list.append(img_link)\n",
    "\n",
    "                img_container = self.driver.find_element(By.XPATH, XPATH_img_container)\n",
    "                thumbnail_list = img_container.find_elements(By.XPATH, XPATH_thumbnails)\n",
    "                for thumbnail in thumbnail_list:\n",
    "                    img_tag = thumbnail.find_element(By.TAG_NAME, 'img')\n",
    "                    thumbnail_link = img_tag.get_attribute('src')\n",
    "                    self.img_list.append(thumbnail_link)\n",
    "\n",
    "                print(self.img_list)\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                print('No images found.')\n",
    "                pass\n",
    "\n",
    "    def create_id(self):\n",
    "        self.link_id = []\n",
    "        self.link_uuid = []\n",
    "        for i in range(len(self.link_list)):\n",
    "            ID = self.link_list[i][-12:]\n",
    "            UUID = uuid.uuid4()\n",
    "            self.link_id.append(ID)\n",
    "            self.link_uuid.append(UUID)\n",
    "    \n",
    "    def collate_info(self):\n",
    "        self.info = {\"id\": self.link_id,\n",
    "                \"uuid\": self.link_uuid,\n",
    "                \"URL\": self.link_list}\n",
    "        print(self.info)\n",
    "        return self.info\n",
    "\n",
    "    def download_images(self, path='.'):\n",
    "        if not os.path.exists(f'{path}/{self.search_term}'):\n",
    "            os.makedirs(f'{path}/{self.search_term}')\n",
    "        \n",
    "        for i, img in enumerate(self.img_list):\n",
    "            urllib.request.urlretrieve(img, f'{path}/{self.search_term}/{self.search_term}{i}.png')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    def web_scraper():\n",
    "        search_term = input('I would like to search for... ')\n",
    "        scraper = Scraper('https://ideas.lego.com', search_term)\n",
    "        try:\n",
    "            scraper.accept_cookies(frame_id=None, XPATH= '//button[@aria-label=\"Reject cookies\"]')\n",
    "            #scraper.explore_product_ideas('//a[@class=\"sub-menu\"][1]', '//div[@class=\"header-link\"][1]')\n",
    "            scraper.search(name='query')\n",
    "            scraper.get_list_links('//*[@id=\"search_results\"]', './div')\n",
    "            time.sleep(2)\n",
    "            scraper.create_id()\n",
    "            scraper.collate_info()\n",
    "            #scraper.create_uuid()\n",
    "            # scraper.scroll_down_bottom()\n",
    "            # time.sleep(2)\n",
    "            # scraper.see_more('//*[@id=\"search-more\"]/a')\n",
    "            # #scraper.scroll_up_top()\n",
    "            # time.sleep(4)\n",
    "        finally: scraper.quit()\n",
    "\n",
    "\n",
    "    web_scraper()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81c5b488f73ff207468821e03890586d8ed279d3a86e8e8e46dd711fd28c910f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('data_coll_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
